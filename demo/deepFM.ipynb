{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepFM demonstration\n",
    "\n",
    "This notebook allows running DeepFM CTR prediction model on custom datasets. \n",
    "\n",
    "To use this note book:\n",
    "\n",
    "\n",
    "1, Clone the FuxiCTR repo\n",
    "```\n",
    "git clone https://github.com/Bernardo1998/FuxiCTR.git\n",
    "```\n",
    "\n",
    "2, Install Required Packages:\n",
    "```\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "3, keep this notebook under \"demo\" folder. For path consistency, please run this notebook under UNIX environment.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1: Make configuration file for custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from fuxictr import datasets\n",
    "from fuxictr.utils import load_config, set_logger, print_to_json\n",
    "from fuxictr.features import FeatureMap\n",
    "from fuxictr.pytorch.torch_utils import seed_everything\n",
    "from fuxictr.pytorch.dataloaders import H5DataLoader\n",
    "from fuxictr.preprocess import FeatureProcessor, build_dataset\n",
    "from model_zoo import DeepFM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, save your csv file under data/your_dataset folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make configuration automatically for custom datasets:\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import yaml\n",
    "\n",
    "def split_save_data_create_yaml(df, config_dir, random_seed, data_root, dataset_name, label_column=None,num_cols=None,train_size=0.33, val_size=0.33):\n",
    "    # Create data_root and config_dir if they don't exist\n",
    "    os.makedirs(data_root, exist_ok=True)\n",
    "    os.makedirs(config_dir, exist_ok=True)\n",
    "    \n",
    "    # Split df into train/val/test\n",
    "    train_df, temp_df = train_test_split(df, test_size=1-train_size, random_state=random_seed)\n",
    "    val_df, test_df = train_test_split(temp_df, test_size=val_size/(1-train_size), random_state=random_seed)\n",
    "    \n",
    "    # File paths\n",
    "    train_path = os.path.join(data_root, 'train_sample.csv')\n",
    "    valid_path = os.path.join(data_root, 'valid_sample.csv')\n",
    "    test_path = os.path.join(data_root, 'test_sample.csv')\n",
    "    \n",
    "    # Save the split dfs\n",
    "    for path, data in zip([train_path, valid_path, test_path], [train_df, val_df, test_df]):\n",
    "        os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "        data.to_csv(path, index=False)\n",
    "\n",
    "    # Assume the last column is always the clk label\n",
    "    if label_column is None:\n",
    "        label_column = df.columns[-1]\n",
    "        feature_cols = df.columns[:(len(df.columns)-1)]\n",
    "    else:\n",
    "        feature_cols = [c for c in df.columns if c != label_column]\n",
    "        \n",
    "    # Check if label_column is numeric\n",
    "    if not pd.api.types.is_numeric_dtype(df[label_column]):\n",
    "        # Convert to 'category' dtype if it's not numeric\n",
    "        df[label_column] = df[label_column].astype('category')\n",
    "\n",
    "        # Convert category labels to codes (integer)\n",
    "        df[label_column] = df[label_column].cat.codes\n",
    "\n",
    "    # Ensure label_column is float\n",
    "    df[label_column] = df[label_column].astype(float)\n",
    "\n",
    "    # Detect num_cols if not given\n",
    "    if num_cols is None:\n",
    "        # Select columns that are of numeric type\n",
    "        # Getting the names of numeric columns\n",
    "        num_cols = df.select_dtypes(include='number').columns\n",
    "\n",
    "    df[num_cols] = df[num_cols].astype(float)\n",
    "    cat_cols = [fc for fc in feature_cols if fc not in num_cols]\n",
    "\n",
    "    feature_cols = []\n",
    "    if len(cat_cols) > 0:\n",
    "        feature_cols.append({\n",
    "                \"name\": cat_cols,\n",
    "                \"active\": True,\n",
    "                \"dtype\": \"str\",\n",
    "                \"type\": \"categorical\"\n",
    "            })\n",
    "    if len(num_cols) > 0:\n",
    "        feature_cols.append({\n",
    "                \"name\": num_cols,\n",
    "                \"active\": True,\n",
    "                \"dtype\": \"float\",\n",
    "                \"type\": \"continuous\"\n",
    "            })\n",
    "    \n",
    "    # YAML configuration\n",
    "    yaml_config = {\n",
    "        dataset_name: {\n",
    "            \"data_root\": data_root,\n",
    "            \"data_format\": \"csv\",\n",
    "            \"train_data\": train_path,\n",
    "            \"valid_data\": valid_path,\n",
    "            \"test_data\": test_path,\n",
    "            \"min_categr_count\": 1,\n",
    "            \"feature_cols\": feature_cols,\n",
    "            \"label_col\": {\"name\": label_column, \"dtype\": \"float\"}\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Save YAML configuration\n",
    "    yaml_path = os.path.join(config_dir, 'dataset_config.yaml')\n",
    "    with open(yaml_path, 'w') as yaml_file:\n",
    "        yaml.dump(yaml_config, yaml_file, default_flow_style=False)\n",
    "\n",
    "    print(f\"Data split and saved. Configuration saved at {yaml_path}.\")\n",
    "\n",
    "def save_model_config(config_dir, experiment_id, dataset_name):\n",
    "    # Configuration dictionary\n",
    "    config = {\n",
    "        \"Base\": {\n",
    "            \"model_root\": \"./checkpoints/\",\n",
    "            \"num_workers\": 3,\n",
    "            \"verbose\": 1,\n",
    "            \"early_stop_patience\": 5,\n",
    "            \"pickle_feature_encoder\": True,\n",
    "            \"save_best_only\": True,\n",
    "            \"eval_steps\": None,\n",
    "            \"debug_mode\": False,\n",
    "            \"group_id\": None,\n",
    "            \"use_features\": None,\n",
    "            \"feature_specs\": None,\n",
    "            \"feature_config\": None\n",
    "        },\n",
    "        experiment_id: {\n",
    "            \"model\": \"DeepFM\",\n",
    "            \"dataset_id\": dataset_name,\n",
    "            \"loss\": \"binary_crossentropy\",\n",
    "            \"metrics\": [\"logloss\", \"AUC\"],\n",
    "            \"task\": \"binary_classification\",\n",
    "            \"optimizer\": \"adam\",\n",
    "            \"hidden_units\": [64, 32],\n",
    "            \"hidden_activations\": \"relu\",\n",
    "            \"net_regularizer\": 0,\n",
    "            \"embedding_regularizer\": 1.e-8,\n",
    "            \"learning_rate\": 1.e-3,\n",
    "            \"batch_norm\": False,\n",
    "            \"net_dropout\": 0,\n",
    "            \"batch_size\": 128,\n",
    "            \"embedding_dim\": 4,\n",
    "            \"epochs\": 30,\n",
    "            \"shuffle\": True,\n",
    "            \"seed\": 2023,\n",
    "            \"monitor\": \"AUC\",\n",
    "            \"monitor_mode\": \"max\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Ensure the configuration directory exists\n",
    "    os.makedirs(config_dir, exist_ok=True)\n",
    "\n",
    "    # YAML file path\n",
    "    yaml_file_path = os.path.join(config_dir, f\"model_config.yaml\")\n",
    "\n",
    "    # Save the configuration as a YAML file\n",
    "    with open(yaml_file_path, 'w') as file:\n",
    "        yaml.dump(config, file, sort_keys=False, default_flow_style=False)\n",
    "\n",
    "    print(f\"Configuration saved to {yaml_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split and saved. Configuration saved at ./config/test_real_data\\dataset_config.yaml.\n",
      "Configuration saved to ./config/test_real_data\\model_config.yaml\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "csv_path = \"../data/test_real_data/real_49998.csv\" # Path to your csv\n",
    "dataset_name = csv_path.split(\"/\")[-1].split(\".\")[0] \n",
    "config_dir = './config/test_real_data' # Path to save your config file\n",
    "random_seed = 42 \n",
    "data_root = '../data/test_real_data' # root dir where your csv files is located. Splitted df will be saved here as well\n",
    "experiment_id = 'DeepFM_test_real_csv'\n",
    "label_col = 'label' # The binary label column indicating clicked/not clicked.\n",
    "num_cols = [] # Numerical features in the data. Leave blank if not numerical features\n",
    "train_size = 0.6 # proportion of train data\n",
    "val_size = 0.2 # proportion of validation data (for cross validation, not final evaluation)\n",
    "\n",
    "df = pd.read_csv(csv_path) \n",
    "\n",
    "# Call the function with your DataFrame and paths\n",
    "split_save_data_create_yaml(df, config_dir, random_seed, data_root, dataset_name, label_col,num_cols,train_size, val_size)\n",
    "save_model_config(config_dir, experiment_id, dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params.keys: dict_keys(['model_root', 'num_workers', 'verbose', 'early_stop_patience', 'pickle_feature_encoder', 'save_best_only', 'eval_steps', 'debug_mode', 'group_id', 'use_features', 'feature_specs', 'feature_config', 'model', 'dataset_id', 'loss', 'metrics', 'task', 'optimizer', 'hidden_units', 'hidden_activations', 'net_regularizer', 'embedding_regularizer', 'learning_rate', 'batch_norm', 'net_dropout', 'batch_size', 'embedding_dim', 'epochs', 'shuffle', 'seed', 'monitor', 'monitor_mode', 'model_id', 'data_format', 'data_root', 'feature_cols', 'label_col', 'min_categr_count', 'test_data', 'train_data', 'valid_data'])\n"
     ]
    }
   ],
   "source": [
    "params = load_config(config_dir, experiment_id)\n",
    "print(\"params.keys:\",params.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-04 09:07:17,474 P76144 INFO Params: {\n",
      "    \"batch_norm\": \"False\",\n",
      "    \"batch_size\": \"128\",\n",
      "    \"data_format\": \"csv\",\n",
      "    \"data_root\": \"../data/test_real_data\",\n",
      "    \"dataset_id\": \"real_49998\",\n",
      "    \"debug_mode\": \"False\",\n",
      "    \"early_stop_patience\": \"3\",\n",
      "    \"embedding_dim\": \"4\",\n",
      "    \"embedding_regularizer\": \"1e-08\",\n",
      "    \"epochs\": \"30\",\n",
      "    \"eval_steps\": \"None\",\n",
      "    \"feature_cols\": \"[{'active': True, 'dtype': 'str', 'name': ['I1', 'I2', 'I3', 'I4', 'I5', 'I6', 'I7', 'I8', 'I9', 'I10', 'I11', 'I12', 'I13', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'C10', 'C11', 'C12', 'C13', 'C14', 'C15', 'C16', 'C17', 'C18', 'C19', 'C20', 'C21', 'C22', 'C23', 'C24', 'C25', 'C26'], 'type': 'categorical'}]\",\n",
      "    \"feature_config\": \"None\",\n",
      "    \"feature_specs\": \"None\",\n",
      "    \"group_id\": \"None\",\n",
      "    \"hidden_activations\": \"relu\",\n",
      "    \"hidden_units\": \"[64, 32]\",\n",
      "    \"label_col\": \"{'dtype': 'float', 'name': 'label'}\",\n",
      "    \"learning_rate\": \"0.001\",\n",
      "    \"loss\": \"binary_crossentropy\",\n",
      "    \"metrics\": \"['logloss', 'AUC']\",\n",
      "    \"min_categr_count\": \"1\",\n",
      "    \"model\": \"DeepFM\",\n",
      "    \"model_id\": \"DeepFM_test_real_csv\",\n",
      "    \"model_root\": \"./checkpoints/\",\n",
      "    \"monitor\": \"AUC\",\n",
      "    \"monitor_mode\": \"max\",\n",
      "    \"net_dropout\": \"0\",\n",
      "    \"net_regularizer\": \"0\",\n",
      "    \"num_workers\": \"3\",\n",
      "    \"optimizer\": \"adam\",\n",
      "    \"pickle_feature_encoder\": \"True\",\n",
      "    \"save_best_only\": \"True\",\n",
      "    \"seed\": \"2023\",\n",
      "    \"shuffle\": \"True\",\n",
      "    \"task\": \"binary_classification\",\n",
      "    \"test_data\": \"../data/test_real_data\\\\test_sample.csv\",\n",
      "    \"train_data\": \"../data/test_real_data\\\\train_sample.csv\",\n",
      "    \"use_features\": \"None\",\n",
      "    \"valid_data\": \"../data/test_real_data\\\\valid_sample.csv\",\n",
      "    \"verbose\": \"1\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# set up logger and random seed\n",
    "set_logger(params)\n",
    "logging.info(\"Params: \" + print_to_json(params))\n",
    "seed_everything(seed=params['seed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2: Setup Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-04 09:07:19,746 P76144 INFO Set up feature processor...\n",
      "2024-02-04 09:07:19,750 P76144 WARNING Skip rebuilding ../data/test_real_data\\real_49998\\feature_map.json. Please delete it manually if rebuilding is required.\n",
      "2024-02-04 09:07:19,751 P76144 INFO Load feature_map from json: ../data/test_real_data\\real_49998\\feature_map.json\n",
      "2024-02-04 09:07:19,759 P76144 INFO Set column index...\n",
      "2024-02-04 09:07:19,759 P76144 INFO Feature specs: {\n",
      "    \"C1\": \"{'source': '', 'type': 'categorical', 'padding_idx': 0, 'oov_idx': 224, 'vocab_size': 225}\",\n",
      "    \"C10\": \"{'source': '', 'type': 'categorical', 'padding_idx': 0, 'oov_idx': 4397, 'vocab_size': 4398}\",\n",
      "    \"C11\": \"{'source': '', 'type': 'categorical', 'padding_idx': 0, 'oov_idx': 2507, 'vocab_size': 2508}\",\n",
      "    \"C12\": \"{'source': '', 'type': 'categorical', 'padding_idx': 0, 'oov_idx': 5155, 'vocab_size': 5156}\",\n",
      "    \"C13\": \"{'source': '', 'type': 'categorical', 'padding_idx': 0, 'oov_idx': 2038, 'vocab_size': 2039}\",\n",
      "    \"C14\": \"{'source': '', 'type': 'categorical', 'padding_idx': 0, 'oov_idx': 26, 'vocab_size': 27}\",\n",
      "    \"C15\": \"{'source': '', 'type': 'categorical', 'padding_idx': 0, 'oov_idx': 2627, 'vocab_size': 2628}\",\n",
      "    \"C16\": \"{'source': '', 'type': 'categorical', 'padding_idx': 0, 'oov_idx': 5331, 'vocab_size': 5332}\",\n",
      "    \"C17\": \"{'source': '', 'type': 'categorical', 'padding_idx': 0, 'oov_idx': 10, 'vocab_size': 11}\",\n",
      "    \"C18\": \"{'source': '', 'type': 'categorical', 'padding_idx': 0, 'oov_idx': 1466, 'vocab_size': 1467}\",\n",
      "    \"C19\": \"{'source': '', 'type': 'categorical', 'padding_idx': 0, 'oov_idx': 673, 'vocab_size': 674}\",\n",
      "    \"C2\": \"{'source': '', 'type': 'categorical', 'padding_idx': 0, 'oov_idx': 419, 'vocab_size': 420}\",\n",
      "    \"C20\": \"{'source': '', 'type': 'categorical', 'padding_idx': 0, 'oov_idx': 5, 'vocab_size': 6}\",\n",
      "    \"C21\": \"{'source': '', 'type': 'categorical', 'padding_idx': 0, 'oov_idx': 5234, 'vocab_size': 5235}\",\n",
      "    \"C22\": \"{'source': '', 'type': 'categorical', 'padding_idx': 0, 'oov_idx': 10, 'vocab_size': 11}\",\n",
      "    \"C23\": \"{'source': '', 'type': 'categorical', 'padding_idx': 0, 'oov_idx': 15, 'vocab_size': 16}\",\n",
      "    \"C24\": \"{'source': '', 'type': 'categorical', 'padding_idx': 0, 'oov_idx': 3590, 'vocab_size': 3591}\",\n",
      "    \"C25\": \"{'source': '', 'type': 'categorical', 'padding_idx': 0, 'oov_idx': 43, 'vocab_size': 44}\",\n",
      "    \"C26\": \"{'source': '', 'type': 'categorical', 'padding_idx': 0, 'oov_idx': 2817, 'vocab_size': 2818}\",\n",
      "    \"C3\": \"{'source': '', 'type': 'categorical', 'padding_idx': 0, 'oov_idx': 5094, 'vocab_size': 5095}\",\n",
      "    \"C4\": \"{'source': '', 'type': 'categorical', 'padding_idx': 0, 'oov_idx': 5294, 'vocab_size': 5295}\",\n",
      "    \"C5\": \"{'source': '', 'type': 'categorical', 'padding_idx': 0, 'oov_idx': 73, 'vocab_size': 74}\",\n",
      "    \"C6\": \"{'source': '', 'type': 'categorical', 'padding_idx': 0, 'oov_idx': 11, 'vocab_size': 12}\",\n",
      "    \"C7\": \"{'source': '', 'type': 'categorical', 'padding_idx': 0, 'oov_idx': 4177, 'vocab_size': 4178}\",\n",
      "    \"C8\": \"{'source': '', 'type': 'categorical', 'padding_idx': 0, 'oov_idx': 130, 'vocab_size': 131}\",\n",
      "    \"C9\": \"{'source': '', 'type': 'categorical', 'padding_idx': 0, 'oov_idx': 4, 'vocab_size': 5}\",\n",
      "    \"I1\": \"{'source': '', 'type': 'categorical', 'padding_idx': 0, 'oov_idx': 22, 'vocab_size': 23}\",\n",
      "    \"I10\": \"{'source': '', 'type': 'categorical', 'padding_idx': 0, 'oov_idx': 8, 'vocab_size': 9}\",\n",
      "    \"I11\": \"{'source': '', 'type': 'categorical', 'padding_idx': 0, 'oov_idx': 12, 'vocab_size': 13}\",\n",
      "    \"I12\": \"{'source': '', 'type': 'categorical', 'padding_idx': 0, 'oov_idx': 12, 'vocab_size': 13}\",\n",
      "    \"I13\": \"{'source': '', 'type': 'categorical', 'padding_idx': 0, 'oov_idx': 52, 'vocab_size': 53}\",\n",
      "    \"I2\": \"{'source': '', 'type': 'categorical', 'padding_idx': 0, 'oov_idx': 536, 'vocab_size': 537}\",\n",
      "    \"I3\": \"{'source': '', 'type': 'categorical', 'padding_idx': 0, 'oov_idx': 102, 'vocab_size': 103}\",\n",
      "    \"I4\": \"{'source': '', 'type': 'categorical', 'padding_idx': 0, 'oov_idx': 52, 'vocab_size': 53}\",\n",
      "    \"I5\": \"{'source': '', 'type': 'categorical', 'padding_idx': 0, 'oov_idx': 6994, 'vocab_size': 6995}\",\n",
      "    \"I6\": \"{'source': '', 'type': 'categorical', 'padding_idx': 0, 'oov_idx': 494, 'vocab_size': 495}\",\n",
      "    \"I7\": \"{'source': '', 'type': 'categorical', 'padding_idx': 0, 'oov_idx': 102, 'vocab_size': 103}\",\n",
      "    \"I8\": \"{'source': '', 'type': 'categorical', 'padding_idx': 0, 'oov_idx': 52, 'vocab_size': 53}\",\n",
      "    \"I9\": \"{'source': '', 'type': 'categorical', 'padding_idx': 0, 'oov_idx': 488, 'vocab_size': 489}\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Set feature_encoder that defines how to preprocess data\n",
    "feature_encoder = FeatureProcessor(feature_cols=params[\"feature_cols\"],\n",
    "                                    label_col=params[\"label_col\"],\n",
    "                                    dataset_id=params[\"dataset_id\"], \n",
    "                                    data_root=params[\"data_root\"])\n",
    "\n",
    "# Build dataset from csv to h5, and remap data paths to h5 files\n",
    "params[\"train_data\"], params[\"valid_data\"], params[\"test_data\"] = \\\n",
    "    build_dataset(feature_encoder, \n",
    "                    train_data=params[\"train_data\"],\n",
    "                    valid_data=params[\"valid_data\"],\n",
    "                    test_data=params[\"test_data\"])\n",
    "\n",
    "# Get feature_map that defines feature specs\n",
    "data_dir = os.path.join(params['data_root'], params['dataset_id'])\n",
    "feature_map = FeatureMap(params['dataset_id'], data_dir)\n",
    "feature_map.load(os.path.join(data_dir, \"feature_map.json\"), params)\n",
    "logging.info(\"Feature specs: \" + print_to_json(feature_map.features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-04 09:07:23,272 P76144 INFO Loading data...\n",
      "2024-02-04 09:07:23,279 P76144 INFO Loading data from h5: ../data/test_real_data\\real_49998\\train.h5\n",
      "2024-02-04 09:07:23,332 P76144 INFO Train samples: total/16499, blocks/1\n",
      "2024-02-04 09:07:23,333 P76144 INFO Loading data from h5: ../data/test_real_data\\real_49998\\valid.h5\n",
      "2024-02-04 09:07:23,353 P76144 INFO Validation samples: total/16999, blocks/1\n",
      "2024-02-04 09:07:23,353 P76144 INFO Loading train and validation data done.\n"
     ]
    }
   ],
   "source": [
    "# Get train and validation data generators from h5\n",
    "train_gen, valid_gen = H5DataLoader(feature_map, \n",
    "                                    stage='train', \n",
    "                                    train_data=params['train_data'],\n",
    "                                    valid_data=params['valid_data'],\n",
    "                                    batch_size=params['batch_size'],\n",
    "                                    shuffle=params['shuffle']).make_iterator()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 3: Setup model and training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-04 09:07:25,120 P76144 INFO Start training: 129 batches/epoch\n",
      "2024-02-04 09:07:25,121 P76144 INFO ************ Epoch=1 start ************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 125/129 [00:05<00:00, 59.14it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-04 09:07:30,659 P76144 INFO Train loss: 0.536044\n",
      "2024-02-04 09:07:30,659 P76144 INFO Evaluation @epoch 1 - batch 129: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:02<00:00, 58.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-04 09:07:32,960 P76144 INFO [Metrics] AUC: 0.727590\n",
      "2024-02-04 09:07:32,961 P76144 INFO Save best model: monitor(max)=0.727590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 129/129 [00:08<00:00, 16.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-04 09:07:33,161 P76144 INFO ************ Epoch=1 end ************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 98%|█████████▊| 126/129 [00:03<00:00, 60.14it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-04 09:07:37,081 P76144 INFO Train loss: 0.382920\n",
      "2024-02-04 09:07:37,082 P76144 INFO Evaluation @epoch 2 - batch 129: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:02<00:00, 61.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-04 09:07:39,243 P76144 INFO [Metrics] AUC: 0.685390\n",
      "2024-02-04 09:07:39,243 P76144 INFO Monitor(max)=0.685390 STOP!\n",
      "2024-02-04 09:07:39,243 P76144 INFO Reduce learning rate on plateau: 0.000100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 129/129 [00:06<00:00, 20.54it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-04 09:07:39,443 P76144 INFO ************ Epoch=2 end ************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 99%|█████████▉| 128/129 [00:03<00:00, 62.41it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-04 09:07:43,253 P76144 INFO Train loss: 0.198809\n",
      "2024-02-04 09:07:43,262 P76144 INFO Evaluation @epoch 3 - batch 129: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:02<00:00, 60.14it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-04 09:07:45,485 P76144 INFO [Metrics] AUC: 0.677030\n",
      "2024-02-04 09:07:45,485 P76144 INFO Monitor(max)=0.677030 STOP!\n",
      "2024-02-04 09:07:45,485 P76144 INFO Reduce learning rate on plateau: 0.000010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 129/129 [00:06<00:00, 20.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-04 09:07:45,684 P76144 INFO ************ Epoch=3 end ************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 97%|█████████▋| 125/129 [00:03<00:00, 61.20it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-04 09:07:49,435 P76144 INFO Train loss: 0.172706\n",
      "2024-02-04 09:07:49,435 P76144 INFO Evaluation @epoch 4 - batch 129: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:02<00:00, 62.82it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-04 09:07:51,559 P76144 INFO [Metrics] AUC: 0.676837\n",
      "2024-02-04 09:07:51,561 P76144 INFO Monitor(max)=0.676837 STOP!\n",
      "2024-02-04 09:07:51,561 P76144 INFO Reduce learning rate on plateau: 0.000001\n",
      "2024-02-04 09:07:51,561 P76144 INFO ********* Epoch==4 early stop *********\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 99%|█████████▉| 128/129 [00:06<00:00, 21.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-04 09:07:51,765 P76144 INFO Training finished.\n",
      "2024-02-04 09:07:51,766 P76144 INFO Load best model: c:\\Research\\FuxiCTR\\demo\\checkpoints\\real_49998\\DeepFM_test_real_csv.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Model initialization and fitting\n",
    "model = DeepFM(feature_map, **params)\n",
    "model.fit(train_gen, validation_data=valid_gen, epochs=params['epochs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show run time record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 4: Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-04 09:08:07,463 P76144 INFO ***** Validation evaluation *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:02<00:00, 62.18it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bernard\\Anaconda3\\envs\\ctr\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2898: FutureWarning: Setting the eps parameter is deprecated and will be removed in 1.5. Instead eps will always havea default value of `np.finfo(y_pred.dtype).eps`.\n",
      "  warnings.warn(\n",
      "2024-02-04 09:08:09,626 P76144 INFO [Metrics] logloss: 0.503698 - AUC: 0.727590\n",
      "2024-02-04 09:08:09,626 P76144 INFO ***** Test evaluation *****\n",
      "2024-02-04 09:08:09,626 P76144 INFO Loading data...\n",
      "2024-02-04 09:08:09,626 P76144 INFO Loading data from h5: ../data/test_real_data\\real_49998\\test.h5\n",
      "2024-02-04 09:08:09,654 P76144 INFO Test samples: total/16500, blocks/1\n",
      "2024-02-04 09:08:09,654 P76144 INFO Loading test data done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 129/129 [00:02<00:00, 61.11it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bernard\\Anaconda3\\envs\\ctr\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2898: FutureWarning: Setting the eps parameter is deprecated and will be removed in 1.5. Instead eps will always havea default value of `np.finfo(y_pred.dtype).eps`.\n",
      "  warnings.warn(\n",
      "2024-02-04 09:08:11,788 P76144 INFO [Metrics] logloss: 0.492791 - AUC: 0.741702\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('logloss', 0.49279085242171367), ('AUC', 0.7417023501482575)])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logging.info('***** Validation evaluation *****')\n",
    "model.evaluate(valid_gen)\n",
    "\n",
    "logging.info('***** Test evaluation *****')\n",
    "test_gen = H5DataLoader(feature_map, \n",
    "                        stage='test',\n",
    "                        test_data=params['test_data'],\n",
    "                        batch_size=params['batch_size'],\n",
    "                        shuffle=False).make_iterator()\n",
    "model.evaluate(test_gen)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ctr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
